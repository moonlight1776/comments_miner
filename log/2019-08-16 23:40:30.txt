round 0 epoch 0
100%|██████████| 1769/1769 [05:31<00:00,  5.38it/s]
 99%|█████████▉| 132/133 [00:05<00:00, 28.38it/s]acc 0.960060286360211
train loss　0.106919, val loss 0.021370
round 0 epoch 1
100%|██████████| 133/133 [00:05<00:00, 26.24it/s]
100%|██████████| 1769/1769 [05:31<00:00,  5.17it/s]
100%|██████████| 133/133 [00:05<00:00, 26.31it/s]
acc 0.9555388093443858
train loss　0.032208, val loss 0.022843
round 1 epoch 0
100%|██████████| 1769/1769 [05:35<00:00,  5.56it/s]
100%|██████████| 133/133 [00:05<00:00, 26.07it/s]
  0%|          | 0/1769 [00:00<?, ?it/s]acc 0.9653353428786737
train loss　0.112293, val loss 0.018475
round 1 epoch 1
100%|██████████| 1769/1769 [05:32<00:00,  5.41it/s]
100%|██████████| 133/133 [00:05<00:00, 25.88it/s]
acc 0.9630746043707611
train loss　0.031659, val loss 0.018287
round 2 epoch 0
100%|██████████| 1769/1769 [05:32<00:00,  5.37it/s]
100%|██████████| 133/133 [00:05<00:00, 26.57it/s]
  0%|          | 0/1769 [00:00<?, ?it/s]acc 0.9562923888470234
train loss　0.111447, val loss 0.022947
round 2 epoch 1
100%|██████████| 1769/1769 [05:31<00:00,  5.32it/s]
 98%|█████████▊| 131/133 [00:04<00:00, 27.40it/s]acc 0.9585531273549359
100%|██████████| 133/133 [00:04<00:00, 26.67it/s]
train loss　0.033259, val loss 0.022816
round 3 epoch 0
100%|██████████| 1769/1769 [05:33<00:00,  5.18it/s]
100%|██████████| 133/133 [00:05<00:00, 26.18it/s]
acc 0.9509803921568627
train loss　0.114108, val loss 0.023686
round 3 epoch 1
100%|██████████| 1769/1769 [05:33<00:00,  5.17it/s]
100%|██████████| 133/133 [00:05<00:00, 26.18it/s]
acc 0.9562594268476622
train loss　0.034606, val loss 0.023169
round 4 epoch 0
100%|██████████| 1769/1769 [05:36<00:00,  5.16it/s]
 98%|█████████▊| 131/133 [00:04<00:00, 27.14it/s]acc 0.9683257918552036
train loss　0.123656, val loss 0.014429
round 4 epoch 1
100%|██████████| 133/133 [00:04<00:00, 27.10it/s]
100%|██████████| 1769/1769 [05:34<00:00,  5.18it/s]
100%|██████████| 133/133 [00:04<00:00, 27.08it/s]
acc 0.971342383107089
train loss　0.038027, val loss 0.013657

batch size 3->10
/home/zhukaihua/anaconda3/envs/nlp/bin/python3.7 "/home/zhukaihua/Desktop/nlp/电商评论挖掘/初赛训练数据 2019-08-01/ner_cate_train.py"
6633
round 0 epoch 0
100%|██████████| 531/531 [01:56<00:00,  4.51it/s]
100%|██████████| 133/133 [00:04<00:00, 26.86it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9577995478522984
train loss　0.037016, val loss 0.021641
round 0 epoch 1
100%|██████████| 531/531 [01:57<00:00,  4.78it/s]
100%|██████████| 133/133 [00:04<00:00, 26.86it/s]
acc 0.9585531273549359
train loss　0.010190, val loss 0.020566
round 0 epoch 2
100%|██████████| 531/531 [01:57<00:00,  4.77it/s]
 98%|█████████▊| 130/133 [00:04<00:00, 28.32it/s]acc 0.9570459683496609
train loss　0.005016, val loss 0.020725
100%|██████████| 133/133 [00:04<00:00, 26.90it/s]
round 1 epoch 0
100%|██████████| 531/531 [01:57<00:00,  4.59it/s]
100%|██████████| 133/133 [00:04<00:00, 26.64it/s]
acc 0.9623210248681235
train loss　0.038500, val loss 0.017852
round 1 epoch 1
100%|██████████| 531/531 [01:57<00:00,  4.61it/s]
 99%|█████████▉| 132/133 [00:04<00:00, 25.63it/s]acc 0.9570459683496609
train loss　0.009798, val loss 0.017720
round 1 epoch 2
100%|██████████| 133/133 [00:04<00:00, 26.87it/s]
100%|██████████| 531/531 [01:58<00:00,  4.60it/s]
 98%|█████████▊| 130/133 [00:04<00:00, 26.83it/s]acc 0.9593067068575735
train loss　0.004264, val loss 0.017883
100%|██████████| 133/133 [00:04<00:00, 26.52it/s]
round 2 epoch 0
100%|██████████| 531/531 [01:59<00:00,  4.61it/s]
100%|██████████| 133/133 [00:04<00:00, 27.24it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9510173323285607
train loss　0.035559, val loss 0.021066
round 2 epoch 1
100%|██████████| 531/531 [01:58<00:00,  4.75it/s]
 99%|█████████▉| 132/133 [00:04<00:00, 28.04it/s]acc 0.9517709118311982
train loss　0.009091, val loss 0.020337
round 2 epoch 2
100%|██████████| 133/133 [00:04<00:00, 27.29it/s]
100%|██████████| 531/531 [01:58<00:00,  4.64it/s]
100%|██████████| 133/133 [00:04<00:00, 27.24it/s]
acc 0.9540316503391107
train loss　0.004337, val loss 0.021089
round 3 epoch 0
100%|██████████| 531/531 [01:58<00:00,  4.41it/s]
100%|██████████| 133/133 [00:04<00:00, 26.74it/s]
acc 0.9562594268476622
train loss　0.036349, val loss 0.019031
round 3 epoch 1
100%|██████████| 531/531 [01:58<00:00,  4.59it/s]
100%|██████████| 133/133 [00:05<00:00, 26.54it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9562594268476622
train loss　0.009854, val loss 0.018376
round 3 epoch 2
100%|██████████| 531/531 [02:02<00:00,  3.95it/s]
 98%|█████████▊| 131/133 [00:05<00:00, 25.00it/s]acc 0.9570135746606335
train loss　0.004684, val loss 0.018371
100%|██████████| 133/133 [00:05<00:00, 25.70it/s]
round 4 epoch 0
# dense ###############################################3
/home/zhukaihua/anaconda3/envs/nlp/bin/python3.7 "/home/zhukaihua/Desktop/nlp/电商评论挖掘/初赛训练数据 2019-08-01/ner_cate_train.py"
# attn pool+concat
/home/zhukaihua/anaconda3/envs/nlp/bin/python3.7 "/home/zhukaihua/Desktop/nlp/电商评论挖掘/初赛训练数据 2019-08-01/ner_cate_train.py"
6633
  0%|          | 0/531 [00:00<?, ?it/s]round 0 epoch 0
100%|██████████| 531/531 [01:50<00:00,  4.71it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9570459683496609
train loss　0.035648, val loss 0.019105
round 0 epoch 1
100%|██████████| 531/531 [01:59<00:00,  4.20it/s]
acc 0.9593067068575735
  0%|          | 0/531 [00:00<?, ?it/s]train loss　0.009922, val loss 0.017913
round 0 epoch 2
100%|██████████| 531/531 [02:05<00:00,  4.65it/s]
acc 0.9623210248681235
train loss　0.004751, val loss 0.017897
round 1 epoch 0
100%|██████████| 531/531 [02:03<00:00,  4.56it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9645817633760362
train loss　0.038269, val loss 0.016625
round 1 epoch 1
100%|██████████| 531/531 [02:02<00:00,  4.37it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9630746043707611
train loss　0.010142, val loss 0.015727
round 1 epoch 2
100%|██████████| 531/531 [02:00<00:00,  4.82it/s]
acc 0.9653353428786737
train loss　0.004465, val loss 0.015884
round 2 epoch 0
100%|██████████| 531/531 [02:01<00:00,  4.53it/s]
acc 0.9525244913338358
train loss　0.035157, val loss 0.020345
round 2 epoch 1
100%|██████████| 531/531 [02:00<00:00,  4.47it/s]
acc 0.9555388093443858
train loss　0.010058, val loss 0.019869
round 2 epoch 2
100%|██████████| 531/531 [01:59<00:00,  4.54it/s]
acc 0.9540316503391107
train loss　0.004970, val loss 0.020988
round 3 epoch 0
100%|██████████| 531/531 [01:59<00:00,  4.50it/s]
acc 0.9547511312217195
train loss　0.036261, val loss 0.019207
round 3 epoch 1
100%|██████████| 531/531 [02:00<00:00,  4.48it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9570135746606335
train loss　0.010260, val loss 0.017642
round 3 epoch 2
100%|██████████| 531/531 [02:01<00:00,  4.51it/s]
acc 0.9570135746606335
train loss　0.005740, val loss 0.017539
round 4 epoch 0
100%|██████████| 531/531 [02:00<00:00,  4.32it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9615384615384616
train loss　0.037377, val loss 0.013959
round 4 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.52it/s]
acc 0.9668174962292609
train loss　0.010923, val loss 0.012271
round 4 epoch 2
100%|██████████| 531/531 [02:00<00:00,  4.41it/s]
acc 0.9683257918552036
train loss　0.005132, val loss 0.012025

# polarity
round 0 epoch 0
100%|██████████| 531/531 [01:59<00:00,  4.55it/s]
acc 0.9773926149208741
train loss　0.016663, val loss 0.008157
round 0 epoch 1
100%|██████████| 531/531 [02:00<00:00,  4.51it/s]
acc 0.975885455915599
train loss　0.005578, val loss 0.009164
round 0 epoch 2
100%|██████████| 531/531 [01:59<00:00,  4.73it/s]
acc 0.9773926149208741
train loss　0.002471, val loss 0.009464
round 1 epoch 0
100%|██████████| 531/531 [02:01<00:00,  4.53it/s]
acc 0.9691032403918614
train loss　0.017253, val loss 0.012651
round 1 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.43it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9698568198944989
train loss　0.005607, val loss 0.013435
round 1 epoch 2
100%|██████████| 531/531 [02:00<00:00,  4.33it/s]
acc 0.9698568198944989
train loss　0.002617, val loss 0.013245
round 2 epoch 0
100%|██████████| 531/531 [02:01<00:00,  4.56it/s]
  0%|          | 0/531 [00:00<?, ?it/s]acc 0.9736247174076865
train loss　0.017310, val loss 0.009617
round 2 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.27it/s]
acc 0.9766390354182366
train loss　0.005708, val loss 0.010279
round 2 epoch 2
100%|██████████| 531/531 [02:01<00:00,  4.30it/s]
acc 0.9766390354182366
train loss　0.002611, val loss 0.009060
# mt ################################################
round 0 epoch 0
100%|██████████| 531/531 [01:55<00:00,  4.56it/s]
cate 0.953278, polar 0.969857, overall 0.927656
train loss　0.029589, val loss 0.015959
round 0 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.44it/s]
  0%|          | 0/531 [00:00<?, ?it/s]cate 0.958553, polar 0.975132, overall 0.936699
train loss　0.008544, val loss 0.014934
round 0 epoch 2
100%|██████████| 531/531 [02:01<00:00,  4.54it/s]
cate 0.958553, polar 0.975885, overall 0.937453
train loss　0.004372, val loss 0.015114
round 1 epoch 0
100%|██████████| 531/531 [02:01<00:00,  4.51it/s]
  0%|          | 0/531 [00:00<?, ?it/s]cate 0.957046, polar 0.966843, overall 0.931424
train loss　0.030420, val loss 0.017515
round 1 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.49it/s]
cate 0.963828, polar 0.972871, overall 0.942728
train loss　0.008671, val loss 0.013529
round 1 epoch 2
100%|██████████| 531/531 [02:01<00:00,  4.61it/s]
cate 0.964582, polar 0.973625, overall 0.944235
train loss　0.004104, val loss 0.014225
round 2 epoch 0
100%|██████████| 531/531 [02:01<00:00,  4.57it/s]
cate 0.948757, polar 0.969103, overall 0.920874
train loss　0.028727, val loss 0.017736
round 2 epoch 1
100%|██████████| 531/531 [02:01<00:00,  4.27it/s]
  0%|          | 0/531 [00:00<?, ?it/s]cate 0.952524, polar 0.972118, overall 0.929164
train loss　0.008597, val loss 0.016772
round 2 epoch 2
100%|██████████| 531/531 [02:01<00:00,  4.62it/s]
cate 0.952524, polar 0.974378, overall 0.929917
train loss　0.004652, val loss 0.016404
