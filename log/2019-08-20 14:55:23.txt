20-Aug-19 14:55:25 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/zhukaihua/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
20-Aug-19 14:55:26 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
20-Aug-19 14:55:26 - extracting archive file /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmpza6sc3d9
20-Aug-19 14:55:28 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

20-Aug-19 14:56:50 - epoch 0, train loss 5.489128, valid loss 3.378950, acc 0.820330, recall 0.883432, f1 0.850712 
20-Aug-19 14:58:11 - epoch 1, train loss 1.895065, valid loss 2.936766, acc 0.868657, recall 0.860947, f1 0.864785 
20-Aug-19 14:59:31 - epoch 2, train loss 1.052917, valid loss 3.497120, acc 0.857721, recall 0.877515, f1 0.867505 
20-Aug-19 15:00:52 - epoch 3, train loss 0.611757, valid loss 4.154076, acc 0.861512, recall 0.883432, f1 0.872334 
20-Aug-19 15:00:53 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/zhukaihua/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
20-Aug-19 15:00:54 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
20-Aug-19 15:00:54 - extracting archive file /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmp_y040izp
20-Aug-19 15:00:56 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

20-Aug-19 15:02:19 - epoch 0, train loss 5.616249, valid loss 3.265104, acc 0.825344, recall 0.886391, f1 0.854779 
20-Aug-19 15:03:40 - epoch 1, train loss 1.913192, valid loss 2.738880, acc 0.866114, recall 0.865089, f1 0.865601 
20-Aug-19 15:05:01 - epoch 2, train loss 1.007981, valid loss 3.304900, acc 0.871840, recall 0.877515, f1 0.874668 
20-Aug-19 15:06:22 - epoch 3, train loss 0.577383, valid loss 4.197378, acc 0.857637, recall 0.880473, f1 0.868905 
20-Aug-19 15:06:23 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/zhukaihua/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
20-Aug-19 15:06:24 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
20-Aug-19 15:06:24 - extracting archive file /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmpl2gtepdl
20-Aug-19 15:06:27 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

20-Aug-19 15:07:49 - epoch 0, train loss 5.909280, valid loss 3.082524, acc 0.805539, recall 0.826947, f1 0.816102 
20-Aug-19 15:09:11 - epoch 1, train loss 2.171970, valid loss 2.696790, acc 0.842710, recall 0.860939, f1 0.851727 
20-Aug-19 15:10:32 - epoch 2, train loss 1.331069, valid loss 3.065316, acc 0.837643, recall 0.860939, f1 0.849131 
20-Aug-19 15:11:57 - epoch 3, train loss 0.870625, valid loss 3.616420, acc 0.864469, recall 0.875155, f1 0.869779 
20-Aug-19 15:11:58 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/zhukaihua/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
20-Aug-19 15:11:59 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
20-Aug-19 15:11:59 - extracting archive file /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmpcsatcteu
20-Aug-19 15:12:01 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

20-Aug-19 15:13:23 - epoch 0, train loss 5.642057, valid loss 3.641916, acc 0.782979, recall 0.885680, f1 0.831169 
20-Aug-19 15:14:45 - epoch 1, train loss 1.996334, valid loss 2.907753, acc 0.818482, recall 0.895307, f1 0.855172 
20-Aug-19 15:16:06 - epoch 2, train loss 1.045637, valid loss 3.037322, acc 0.835227, recall 0.884477, f1 0.859147 
20-Aug-19 15:17:27 - epoch 3, train loss 0.621181, valid loss 3.779140, acc 0.840159, recall 0.888688, f1 0.863743 
20-Aug-19 15:17:28 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/zhukaihua/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
20-Aug-19 15:17:29 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
20-Aug-19 15:17:29 - extracting archive file /home/zhukaihua/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmp32n99arp
20-Aug-19 15:17:31 - Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

20-Aug-19 15:18:53 - epoch 0, train loss 5.593330, valid loss 3.364408, acc 0.825162, recall 0.868781, f1 0.846410 
20-Aug-19 15:20:14 - epoch 1, train loss 1.943232, valid loss 2.666159, acc 0.850657, recall 0.885572, f1 0.867764 
20-Aug-19 15:21:35 - epoch 2, train loss 1.061856, valid loss 3.373769, acc 0.841242, recall 0.893035, f1 0.866365 
20-Aug-19 15:22:56 - epoch 3, train loss 0.631929, valid loss 3.995056, acc 0.852923, recall 0.879975, f1 0.866238 
